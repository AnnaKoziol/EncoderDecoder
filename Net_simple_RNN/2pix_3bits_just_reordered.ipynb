{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pix1 dig: 2, bin: ['0', '1', '0']\n",
      "pix2 dig: 3, bin: ['1', '1', '0']\n",
      "input seq: [0 0 1 1 0 1]\n",
      "output seq: [0 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "pixel_depth=3\n",
    "\n",
    "lowerBound=0\n",
    "upperBound=pow(2,pixel_depth-1)\n",
    "\n",
    "pix1=random.randint(lowerBound,upperBound)\n",
    "pix2=random.randint(lowerBound,upperBound)\n",
    "pix1_bin=bin(pix1)[2:]\n",
    "pix2_bin=bin(pix2)[2:]\n",
    "pix1_bin_padded = list(reversed('0'*(pixel_depth-len(pix1_bin))+pix1_bin))\n",
    "pix2_bin_padded = list(reversed('0'*(pixel_depth-len(pix2_bin))+pix2_bin))\n",
    "\n",
    "  #interleave pix1 and pix2\n",
    "input_seq_bin = pix1_bin_padded + pix2_bin_padded\n",
    "input_seq_bin[::2] = list(reversed(pix1_bin_padded))\n",
    "input_seq_bin[1::2] = list(reversed(pix2_bin_padded))\n",
    "output_seq_bin = pix1_bin_padded + pix2_bin_padded\n",
    "\n",
    "input_seq_bin = np.array(input_seq_bin, dtype=np.int)\n",
    "output_seq_bin = np.array(output_seq_bin, dtype=np.int)\n",
    "\n",
    "testFlag=1\n",
    "if testFlag == 1:\n",
    "    print('pix1 dig: {}, bin: {}'.format(pix1, pix1_bin_padded))\n",
    "    print('pix2 dig: {}, bin: {}'.format(pix2, pix2_bin_padded))\n",
    "    print('input seq: {}'.format(input_seq_bin))\n",
    "    print('output seq: {}'.format(output_seq_bin))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Avg. Loss for last 500 samples = inf\n",
      "Final total loss is:tensor(0.2241)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "random.seed(10)\n",
    "\n",
    "def getSample(pixel_depth, testFlag):\n",
    "    lowerBound=0\n",
    "    upperBound=pow(2,pixel_depth-1)\n",
    "\n",
    "    pix1=random.randint(lowerBound,upperBound)\n",
    "    pix2=random.randint(lowerBound,upperBound)\n",
    "    pix1_bin=bin(pix1)[2:]\n",
    "    pix2_bin=bin(pix2)[2:]\n",
    "    pix1_bin_padded = list(reversed('0'*(pixel_depth-len(pix1_bin))+pix1_bin))\n",
    "    pix2_bin_padded = list(reversed('0'*(pixel_depth-len(pix2_bin))+pix2_bin))\n",
    "\n",
    "    #interleave pix1 and pix2, MSB first\n",
    "    input_seq_bin = pix1_bin_padded + pix2_bin_padded\n",
    "    input_seq_bin[::2] = list(reversed(pix1_bin_padded))\n",
    "    input_seq_bin[1::2] = list(reversed(pix2_bin_padded))\n",
    "\n",
    "    output_seq_bin = pix1_bin_padded + pix2_bin_padded\n",
    "\n",
    "    #cast output to numpy array\n",
    "    input_seq_bin = np.array(input_seq_bin, dtype=np.int)\n",
    "    output_seq_bin = np.array(output_seq_bin, dtype=np.int)\n",
    "\n",
    "    if testFlag == 1:\n",
    "        print('pix1 dig: {}, bin: {}'.format(pix1, pix1_bin_padded))\n",
    "        print('pix2 dig: {}, bin: {}'.format(pix2, pix2_bin_padded))\n",
    "        print('input seq: {}'.format(input_seq_bin))\n",
    "        print('output seq: {}'.format(output_seq_bin))\n",
    "\n",
    "    return input_seq_bin, output_seq_bin\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "  def __init__(self, inputDim, hiddenDim, outputDim):\n",
    "    super(Model, self).__init__()\n",
    "    self.inputDim = inputDim\n",
    "    self.hiddenDim = hiddenDim\n",
    "    self.outputDim = outputDim\n",
    "    self.rnn = nn.RNN(inputDim, hiddenDim)\n",
    "    self.outputLayer = nn.Linear(hiddenDim, outputDim)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "  def forward(self, x):\n",
    "    #size of x is T x B x featDim\n",
    "    #B = 1 is dummy batch dimension added, because pytorch mandates it\n",
    "    #if you want B as first dimension of x then specify batchFirst=True when LSTM is initalized\n",
    "    #T,D  = x.size(0), x.size(1)\n",
    "    #batch is a must\n",
    "    out,hidden = self.rnn(x.unsqueeze(1)) #x has two  dimensions  seqLen *batch* FeatDim=2\n",
    "    T,B,D  = out.size(0), out.size(1), out.size(2)\n",
    "    out = out.contiguous()\n",
    "    out = out.view(B*T, D)\n",
    "    outputLayerActivations = self.outputLayer(out)\n",
    "    outputSigmoid = self.sigmoid(outputLayerActivations)\n",
    "    return outputSigmoid\n",
    "\n",
    "inputDim = 1 # two bits each from each of the String\n",
    "outputDim = 1 # one output node which would output a zero or 1\n",
    "\n",
    "rnnSize=10\n",
    "\n",
    "lossFunction = nn.MSELoss()\n",
    "model = Model(inputDim, rnnSize, outputDim)\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "epochs=10000\n",
    "totalLoss= float(\"inf\")\n",
    "\n",
    "print(\" Avg. Loss for last 500 samples = %lf\"%(totalLoss))\n",
    "totalLoss=0\n",
    "for i in range(0,epochs): # average the loss over 200 samples\n",
    "    stringLen=4\n",
    "    testFlag=0\n",
    "    x,y = getSample(stringLen, testFlag)\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    x_var=autograd.Variable(torch.from_numpy(x).unsqueeze(1).float()) #convert to torch tensor and variable\n",
    "    # unsqueeze() is used to add the extra dimension since\n",
    "    # your input need to be of t*batchsize*featDim; you cant do away with the batch in pytorch\n",
    "    seqLen = x_var.size(0)\n",
    "    x_var = x_var.contiguous()\n",
    "    y_var = autograd.Variable(torch.from_numpy(y).float())\n",
    "    finalScores = model(x_var)\n",
    "\n",
    "    loss = lossFunction(finalScores,y_var)\n",
    "    totalLoss+=loss.data\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "totalLoss = totalLoss/epochs\n",
    "print('Final total loss is:' + str(totalLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input numbers and their sum  are 25   33   58\n",
      "binary strings are 11001   100001   111010\n",
      "input numbers and their sum  are 108   78   186\n",
      "binary strings are 1101100   1001110   10111010\n",
      "input numbers and their sum  are 12   56   68\n",
      "binary strings are 1100   111000   1000100\n",
      "input numbers and their sum  are 108   80   188\n",
      "binary strings are 1101100   1010000   10111100\n",
      "input numbers and their sum  are 72   112   184\n",
      "binary strings are 1001000   1110000   10111000\n",
      "input numbers and their sum  are 110   5   115\n",
      "binary strings are 1101110   101   1110011\n",
      "input numbers and their sum  are 55   41   96\n",
      "binary strings are 110111   101001   1100000\n",
      "input numbers and their sum  are 53   18   71\n",
      "binary strings are 110101   10010   1000111\n",
      "input numbers and their sum  are 8   36   44\n",
      "binary strings are 1000   100100   101100\n",
      "input numbers and their sum  are 69   82   151\n",
      "binary strings are 1000101   1010010   10010111\n"
     ]
    }
   ],
   "source": [
    "###### Testing the model ######\n",
    "\n",
    "pixel_depth = 3\n",
    "testFlag=1\n",
    "\n",
    "for i in range (0,10):\n",
    "\tx,y=getSample(pixel_depth,testFlag)\n",
    "\tx_var=autograd.Variable(torch.from_numpy(x).unsqueeze(1).float())\n",
    "\ty_var=autograd.Variable(torch.from_numpy(y).float())\n",
    "\tseqLen=x_var.size(0)\n",
    "\tx_var= x_var.contiguous()\n",
    "\tfinalScores = model(x_var).data.t()\n",
    "\t#print(finalScores)\n",
    "\tbits=finalScores.gt(0.5)\n",
    "\tbits=bits[0].numpy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pix1 dig: 46, bin: ['0', '1', '1', '1', '0', '1', '0']\n",
      "pix2 dig: 47, bin: ['1', '1', '1', '1', '0', '1', '0']\n",
      "input seq: [0 0 1 1 0 0 1 1 1 1 1 1 0 1]\n",
      "output seq: [0 1 1 1 0 1 0 1 1 1 1 0 1 0]\n",
      "sum predicted by RNN is  [ True  True  True  True  True  True False False False False False False\n",
      " False False]\n",
      "##################################################\n",
      "pix1 dig: 59, bin: ['1', '1', '0', '1', '1', '1', '0']\n",
      "pix2 dig: 63, bin: ['1', '1', '1', '1', '1', '1', '0']\n",
      "input seq: [0 0 1 1 1 1 1 1 0 1 1 1 1 1]\n",
      "output seq: [1 1 0 1 1 1 0 1 1 1 1 1 1 0]\n",
      "sum predicted by RNN is  [ True  True  True  True  True  True  True  True  True  True False False\n",
      " False False]\n",
      "##################################################\n",
      "pix1 dig: 64, bin: ['0', '0', '0', '0', '0', '0', '1']\n",
      "pix2 dig: 19, bin: ['1', '1', '0', '0', '1', '0', '0']\n",
      "input seq: [1 0 0 0 0 1 0 0 0 0 0 1 0 1]\n",
      "output seq: [0 0 0 0 0 0 1 1 1 0 0 1 0 0]\n",
      "sum predicted by RNN is  [False False False False False False False False False False False False\n",
      " False False]\n",
      "##################################################\n",
      "pix1 dig: 42, bin: ['0', '1', '0', '1', '0', '1', '0']\n",
      "pix2 dig: 62, bin: ['0', '1', '1', '1', '1', '1', '0']\n",
      "input seq: [0 0 1 1 0 1 1 1 0 1 1 1 0 0]\n",
      "output seq: [0 1 0 1 0 1 0 0 1 1 1 1 1 0]\n",
      "sum predicted by RNN is  [ True  True  True  True  True  True  True  True False False False False\n",
      " False False]\n",
      "##################################################\n",
      "pix1 dig: 16, bin: ['0', '0', '0', '0', '1', '0', '0']\n",
      "pix2 dig: 12, bin: ['0', '0', '1', '1', '0', '0', '0']\n",
      "input seq: [0 0 0 0 1 0 0 1 0 1 0 0 0 0]\n",
      "output seq: [0 0 0 0 1 0 0 0 0 1 1 0 0 0]\n",
      "sum predicted by RNN is  [False False False False False False False False False False False False\n",
      " False False]\n",
      "##################################################\n",
      "pix1 dig: 27, bin: ['1', '1', '0', '1', '1', '0', '0']\n",
      "pix2 dig: 12, bin: ['0', '0', '1', '1', '0', '0', '0']\n",
      "input seq: [0 0 0 0 1 0 1 1 0 1 1 0 1 0]\n",
      "output seq: [1 1 0 1 1 0 0 0 0 1 1 0 0 0]\n",
      "sum predicted by RNN is  [False False False False False False False False False False False False\n",
      " False False]\n",
      "##################################################\n",
      "pix1 dig: 28, bin: ['0', '0', '1', '1', '1', '0', '0']\n",
      "pix2 dig: 16, bin: ['0', '0', '0', '0', '1', '0', '0']\n",
      "input seq: [0 0 0 0 1 1 1 0 1 0 0 0 0 0]\n",
      "output seq: [0 0 1 1 1 0 0 0 0 0 0 1 0 0]\n",
      "sum predicted by RNN is  [False False False False False False False False False False False False\n",
      " False False]\n",
      "##################################################\n",
      "pix1 dig: 11, bin: ['1', '1', '0', '1', '0', '0', '0']\n",
      "pix2 dig: 23, bin: ['1', '1', '1', '0', '1', '0', '0']\n",
      "input seq: [0 0 0 0 0 1 1 0 0 1 1 1 1 1]\n",
      "output seq: [1 1 0 1 0 0 0 1 1 1 0 1 0 0]\n",
      "sum predicted by RNN is  [ True  True False False False False False False False False False False\n",
      " False False]\n",
      "##################################################\n",
      "pix1 dig: 7, bin: ['1', '1', '1', '0', '0', '0', '0']\n",
      "pix2 dig: 53, bin: ['1', '0', '1', '0', '1', '1', '0']\n",
      "input seq: [0 0 0 1 0 1 0 0 1 1 1 0 1 1]\n",
      "output seq: [1 1 1 0 0 0 0 1 0 1 0 1 1 0]\n",
      "sum predicted by RNN is  [ True False False False False False False False False False False False\n",
      " False False]\n",
      "##################################################\n",
      "pix1 dig: 48, bin: ['0', '0', '0', '0', '1', '1', '0']\n",
      "pix2 dig: 35, bin: ['1', '1', '0', '0', '0', '1', '0']\n",
      "input seq: [0 0 1 1 1 0 0 0 0 0 0 1 0 1]\n",
      "output seq: [0 0 0 0 1 1 0 1 1 0 0 0 1 0]\n",
      "sum predicted by RNN is  [False False False False False False False False  True  True False False\n",
      " False False]\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "###### Testing the model ######\n",
    "\n",
    "stringLen=7\n",
    "testFlag=1\n",
    "# test the network on 10 random binary string addition cases where stringLen=4\n",
    "for i in range (0,10):\n",
    "\tx,y=getSample(stringLen,testFlag)\n",
    "\tx_var=autograd.Variable(torch.from_numpy(x).unsqueeze(1).float())\n",
    "\ty_var=autograd.Variable(torch.from_numpy(y).float())\n",
    "\tseqLen=x_var.size(0)\n",
    "\tx_var= x_var.contiguous()\n",
    "\tfinalScores = model(x_var).data.t()\n",
    "\t#print(finalScores)\n",
    "\tbits=finalScores.gt(0.5)\n",
    "\tbits=bits[0].numpy()\n",
    "\n",
    "\tprint ('sum predicted by RNN is ',bits[::-1])\n",
    "\tprint('##################################################')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}