{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "from torchvision import models\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "    # Define data directory\n",
    "data_dir = Path(os.getcwd()) / 'my_data'\n",
    "training_dir = data_dir / 'training'\n",
    "x_dir = training_dir / 'x'\n",
    "y_dir = training_dir / 'y'\n",
    "\n",
    "    # Read data\n",
    "indexes = range(0,99) #range(0,6999)\n",
    "indexes_leading_zero = [str(index).zfill(5) for index in indexes]\n",
    "files_names = [index + '.bin' for index in indexes_leading_zero]\n",
    "x = np.array([np.fromfile(x_dir / file, 'uint8') for file in files_names])\n",
    "y = np.array([np.fromfile(y_dir / file, 'uint8') for file in files_names])\n",
    "\n",
    "train_data = torch.from_numpy(x)\n",
    "train_data = train_data.unsqueeze(1)\n",
    "train_data = train_data.to(torch.float)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=False)\n",
    "\n",
    "test_data = torch.from_numpy(y)\n",
    "test_data = test_data.unsqueeze(1)\n",
    "test_data = test_data.to(torch.float)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[[1., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 1.,  ..., 0., 1., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 0., 1.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([99, 1, 1792])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data))\n",
    "print(test_data)\n",
    "test_data.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "# Define the Convolutional Autoencoder\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=5, padding=0, stride=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=5, padding=0, stride=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=4, padding=0, stride=1)\n",
    "\n",
    "        self.pool = nn.AvgPool1d(2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(8)\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "\n",
    "        self.t_conv1 = nn.ConvTranspose1d(32, 16, 5, padding=0, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose1d(16, 8, 6, padding=0, stride=2)\n",
    "        self.t_conv3 = nn.ConvTranspose1d(8, 1, 6, padding=0, stride=2)\n",
    "\n",
    "        self.t_bn1 = nn.BatchNorm1d(16)\n",
    "        self.t_bn2 = nn.BatchNorm1d(8)\n",
    "        self.t_bn3 = nn.BatchNorm1d(1)\n",
    "\n",
    "    def forward(self, out):\n",
    "        # Encoder\n",
    "        out = self.conv1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.bn1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        # Decoder\n",
    "        out = self.t_conv1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.t_bn1(out)\n",
    "\n",
    "        out = self.t_conv2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.t_bn2(out)\n",
    "\n",
    "        out = self.t_conv3(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.t_bn3(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 8, 1788]              48\n",
      "         AvgPool1d-2               [-1, 8, 894]               0\n",
      "       BatchNorm1d-3               [-1, 8, 894]              16\n",
      "            Conv1d-4              [-1, 16, 890]             656\n",
      "         AvgPool1d-5              [-1, 16, 445]               0\n",
      "       BatchNorm1d-6              [-1, 16, 445]              32\n",
      "            Conv1d-7              [-1, 32, 442]           2,080\n",
      "         AvgPool1d-8              [-1, 32, 221]               0\n",
      "       BatchNorm1d-9              [-1, 32, 221]              64\n",
      "  ConvTranspose1d-10              [-1, 16, 445]           2,576\n",
      "      BatchNorm1d-11              [-1, 16, 445]              32\n",
      "  ConvTranspose1d-12               [-1, 8, 894]             776\n",
      "      BatchNorm1d-13               [-1, 8, 894]              16\n",
      "  ConvTranspose1d-14              [-1, 1, 1792]              49\n",
      "      BatchNorm1d-15              [-1, 1, 1792]               2\n",
      "================================================================\n",
      "Total params: 6,347\n",
      "Trainable params: 6,347\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.90\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.93\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Print model summary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ConvAutoencoder().to(device)\n",
    "\n",
    "summary(model, (1, 1792))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "#n_epochs, learning_rate, weight_decay\n",
    "\n",
    "def train(parameters, result_dir, excel_path):\n",
    "    #Open excel file\n",
    "    workbook = load_workbook(excel_path)\n",
    "    worksheet = workbook.get_sheet_by_name('Results')\n",
    "\n",
    "    for idx, param in tqdm(enumerate(parameters), total=len(parameters)):\n",
    "        learning_rate = param['learning_rate']\n",
    "        weight_decay = param['weight_decay']\n",
    "        n_epochs = param['n_epochs']\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "        device = get_device()\n",
    "        model.to(device)\n",
    "\n",
    "        loss_history = []\n",
    "        for epoch in range(1, n_epochs+1):\n",
    "            # monitor training loss\n",
    "            train_loss = 0.0\n",
    "\n",
    "            #Training\n",
    "            for data in train_loader:\n",
    "                target = data\n",
    "                target = target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(target)\n",
    "                loss = criterion(outputs, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()*target.size(0)\n",
    "\n",
    "            train_loss = train_loss/len(train_loader)\n",
    "            loss_history.append(train_loss / len(train_data))\n",
    "            #print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "\n",
    "        #Plot history\n",
    "        plt.plot(loss_history)\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('loss')\n",
    "\n",
    "        #Save plot\n",
    "        fig_name = 'e_{:04}_lr_{:1.4f}_wd_{:1.4f}.png'.format(n_epochs,learning_rate, weight_decay)\n",
    "        file_path = Path(result_dir) / fig_name\n",
    "        plt.savefig(file_path)\n",
    "        plt.close()\n",
    "\n",
    "        #Save results to excel\n",
    "        worksheet.cell(idx+4, 2).value = '{:04}'.format(idx)\n",
    "        worksheet.cell(idx+4, 3).value = '{:1.4f}'.format(learning_rate)\n",
    "        worksheet.cell(idx+4, 4).value = '{:1.4f}'.format(weight_decay)\n",
    "        worksheet.cell(idx+4, 5).value = '{:04}'.format(n_epochs)\n",
    "        worksheet.cell(idx+4, 6).value = '{:.6f}'.format(train_loss)\n",
    "\n",
    "        workbook.save(excel_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-140-33a4d590c11d>:13: DeprecationWarning: Call to deprecated function get_sheet_by_name (Use wb[sheetname]).\n",
      "  worksheet = workbook.get_sheet_by_name('Results')\n",
      "100%|██████████| 484/484 [4:16:18<00:00, 31.77s/it]  \n"
     ]
    }
   ],
   "source": [
    "parameters = []\n",
    "# for epochs in range(16,64+16,16):\n",
    "#     for lr in range(0.000,0.1+0.005,0.005):\n",
    "#         for wd in range(0.000,0.1+0.005,0.005):\n",
    "#             parameters.append({'n_epochs': epochs, 'learning_rate': lr, 'weight_decay': wd})\n",
    "for epochs in np.arange(16,64+16,16):\n",
    "    for lr in np.arange(0.000,0.05+0.005,0.005):\n",
    "        for wd in np.arange(0.000,0.05+0.005,0.005):\n",
    "            parameters.append({'n_epochs': epochs, 'learning_rate': lr, 'weight_decay': wd})\n",
    "\n",
    "result_dir = r'D:\\AGH\\Projects\\ANN\\CNN_autoencoder\\results\\my_laptop\\Training_0000'\n",
    "excel_path = os.path.join(result_dir, 'Training_0000.xlsx')\n",
    "\n",
    "train(parameters=parameters, result_dir=result_dir, excel_path=excel_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}